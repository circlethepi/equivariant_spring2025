{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import notebook, datasets, build_models,caluclate_basis, custom_blocks, train, utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import argparse\n",
    "import wandb\n",
    "from tqdm import tqdm   \n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "\n",
    "    train_loader, val_loader, test_loader = datasets.get_dataloaders(config, logfile=None, summaryfile=None, log=False) \n",
    "\n",
    "    model = build_models.build_model_from_args(config)\n",
    "\n",
    "    if config.criterion == \"CrossEntropyLoss\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif config.criterion == \"MSELoss\":\n",
    "        criterion = nn.MSELoss()\n",
    "    else:\n",
    "        raise ValueError(f\"Criterion {criterion} not supported\")\n",
    "    \n",
    "    if config.optimizer == \"Adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "    elif config.optimizer == \"SGD\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=config.lr)\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer {optimizer} not supported\")\n",
    "    \n",
    "    return model, train_loader, val_loader, test_loader, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(arch=['64', 'M', '128', 'M'], \n",
    "                                 batch_norm=False,\n",
    "                                 bias=True,\n",
    "                                 classifier_layers=[256],\n",
    "                                 classifier_bias= True,\n",
    "                                 classifier_dropout= 0,\n",
    "                                 avgpool=True,\n",
    "                                 avgpool_size=[1,1],  # Adjusted avgpool size to (1, 1)\n",
    "                                 dataset=\"mnist\",\n",
    "                                 input_height = 28,\n",
    "                                 input_width = 28,\n",
    "                                 greyscale=True,\n",
    "                                 n_classes= 10,\n",
    "                                 epochs=10, \n",
    "                                 batch_size=64,\n",
    "                                 optimizer=\"Adam\",\n",
    "                                 weight_normalization=False,\n",
    "                                 lr=0.001,\n",
    "                                 criterion=\"CrossEntropyLoss\",\n",
    "                                 seed=42,\n",
    "                                 save_checkpoints=False,\n",
    "                                 save_dir = \"\",\n",
    "                                 checkpoint_type = \"epoch\",\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"custom-vgg-model\", config=hyperparameters)\n",
    "config = wandb.config\n",
    "\n",
    "model, train_loader, val_loader, test_loader, criterion, optimizer = make(config)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# and use them to train the model\n",
    "train.train(config, model, train_loader, val_loader, test_loader,criterion, optimizer)\n",
    "#finish run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet-18 model\n",
    "def load_resnet18(n_classes):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    # Modify the final fully connected layer to have n_classes output units\n",
    "    model.fc = nn.Linear(model.fc.in_features, n_classes)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
